# -*- coding: utf-8 -*-
"""prompt_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/193yPVgH0qDM1UFbCauuTZDgcyLo6Gvg2

### Sarcasm Detection with Prompt Engineering & LLMs

This notebook explores **sarcasm detection** using a Reddit sarcasm dataset from Kaggle. Sarcasm is difficult for machines to understand because the literal meaning of a comment often contradicts its intended meaning.

I used the following steps in this project:

1.   Load and preprocess the labeled dataset (Reddit comments labeled as sarcastic = 1, not sarcastic = 0).

2.   Use parent comments for context (since sarcasm often depends on what someone is replying to).

3.   Test different prompting techniques (Few-Shot, Role, Chain-of-Thought, Step-Back, etc.) with a sarcasm-tuned LLaMA model.

4. Compare results across techniques using standard metrics like accuracy, precision, recall, and F1 score.

**The main goal of this project is to analyze and show how prompt engineering and context can improve sarcasm detection.**
"""

!pip install kaggle
!pip install scikit-learn transformers torch

!pip install llama-cpp-python --force-reinstall --no-cache-dir --verbose --extra-index-url https://jllllll.github.io/llama-cpp-python-cuBLAS-a-cuda-12.2-builds/wheels/cuBLAS-a-cuda-12.2/

!chmod 600 /content/kaggle.json

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content"

!kaggle datasets download -d danofer/sarcasm

!unzip sarcasm.zip -d sarcasm_data

import re
import torch
import os
import pandas as pd

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from transformers import AutoTokenizer, AutoModelForCausalLM

pd.set_option("display.max_colwidth", None)

df = pd.read_csv("sarcasm_data/train-balanced-sarcasm.csv")
df.head()

# Check for noise in the text data including emojis
mask = df['comment'].str.contains(r"http|www|@\w+|[!?]{2,}|[\U0001F600-\U0001F64F]", regex=True, na=False)
df[mask][['comment']].head(10)

# Just the URL's and spaces
mask = df['comment'].str.contains(r"http|www|\s{2,}", regex=True, na=False)
df[mask][['comment']].head(10)



"""
### Dataset Prep
"""

# Since the task is sarcasm detection, I chose to keep punctuation marks (e.g., "!"", "...""), capitalization, and emojis, because these often carry strong cues of sarcastic tone.
# I only cleaned URLs and excessive whitespace.
def clean_comment(text):
    text = str(text).lower()
    text = re.sub(r"http\S+|www\S+", " URL ", text)   # replace URLs
    text = re.sub(r"\s+", " ", text).strip()          # normalize spaces
    return text

df['clean_comment'] = df['comment'].apply(clean_comment)
df.head()

print(df.shape)

df.tail()

# Keep only the necessary columns
df = df[['clean_comment', 'parent_comment', 'label']]
df.head(1)

# Sample both class examples to use in prompts
num_examples_per_class = 3

# having label 0 (Not Sarcastic)
examples_0 = df[df['label'] == 0].sample(n=num_examples_per_class, random_state=99)

# having label 1 (Sarcastic)
examples_1 = df[df['label'] == 1].sample(n=num_examples_per_class, random_state=99)

few_shot_examples = pd.concat([examples_0, examples_1]).reset_index(drop=True)
few_shot_examples

temp_df = few_shot_examples.copy()

temp_df['clean_comment'] = temp_df['clean_comment'].astype(str)
temp_df['parent_comment'] = temp_df['parent_comment'].astype(str)

temp_df['comment_len'] = temp_df['clean_comment'].apply(lambda x: len(x.split()))
temp_df['parent_len'] = temp_df['parent_comment'].apply(lambda x: len(x.split()))
temp_df['combined_len'] = temp_df['comment_len'] + temp_df['parent_len']

temp_df[['comment_len', 'parent_len', 'combined_len']]



# drop few-shot examples from original dataset
df_remaining = df.drop(few_shot_examples.index).reset_index(drop=True)

# sample 2 target rows per label from remaining dataset for testing prompt responses
test_0 = df_remaining[df_remaining['label'] == 0].sample(n=2, random_state=99)
test_1 = df_remaining[df_remaining['label'] == 1].sample(n=2, random_state=99)
df_test = pd.concat([test_0, test_1]).reset_index(drop=True)

df_len = df_test.copy()
df_len['clean_comment'] = df_len['clean_comment'].astype(str)
df_len['parent_comment'] = df_len['parent_comment'].astype(str)

df_len['comment_len'] = df_len['clean_comment'].apply(lambda x: len(x.split()))
df_len['parent_len'] = df_len['parent_comment'].apply(lambda x: len(x.split()))
df_len['combined_len'] = df_len['comment_len'] + df_len['parent_len']

print(df_len[['comment_len', 'parent_len', 'combined_len']])



"""### Prompt Engineering"""

# Chosen Prompting Techniques & Justifications

# Few-Shot Prompting
# Providing labeled examples of sarcastic and non-sarcastic comments before the test input helps the model learn subtle cues such as punctuations and mismatched tone-intent.

# Role Prompting
# Instructing the model to act as a critic specializing in sarcasm detection focuses its reasoning on chat patterns, tone shifts, and cues that indicate sarcasm.

# Rephrase and Respond (RaR)
# Asking the model to first rewrite the comment literally before classification exposes mismatches between literal meaning and implied intent.

# Chain-of-Thought (CoT) Prompting
# Guiding the model to think step-by-step ensures it explicitly analyzes context, tone, and contradictions before deciding, improving detection in borderline cases.

# Step-Back Prompting
# Having the model first describe the general situation/context before answering helps it avoid misclassification.

# Self-Refine
# Letting the model critique and improve its own answer helps catch false positives where tone is casually humorous but not actually sarcastic.

# Chain-of-Verification (COVE)
# Prompting the model to ask itself related verification questions for example the model might ask itself: Is this praise meant literally or is it mocking?

prompt_templates_direct = {
    "Basic": "Classify the following comment as sarcastic or not. 0 for non-sarcastic, 1 for sarcastic. RETURN Label: 0 or 1. Reason:[1-2 sentences]. Comment: '{comment}'",
    "Role": "You are a critic specializing in sarcasm detection. Classify the comment in a conversation as sarcastic or not & Provide your reasoning at the end. 0 for non-sarcastic, 1 for sarcastic. RETURN Label: 0 or 1. Reason:[1-2 sentences]. Comment: '{comment}'",
    "Role-Context": "You are a critic specializing in sarcasm detection. Classify the comment in a conversation as sarcastic or not & Provide your reasoning at the end. 0 for non-sarcastic, 1 for sarcastic. RETURN Label: 0 or 1. Reason:[1-2 sentences]. Comment: '{comment}' in response to: '{parent}'",
    "Rephrase-and-Respond": "Your task is to classify the comment as sarcastic or not. Rephrase the comment, then classify if sarcastic & Give your reasoning at the end. 0 for non-sarcastic, 1 for sarcastic. Comment: '{comment}' in response to: '{parent}'. RETURN Label: 0 or 1. Reason:[1-2 sentences].",
    "Chain-of-Thought": "Your task is to classify the comment as sarcastic or not. Think step by step about the context and the reply before classifying & Provide your chain of thought/reasoning at the end. Comment: '{comment}' in response to: '{parent}'. RETURN Label: 0 for non-sarcastic, 1 for sarcastic. Reason:[1-2 sentences].",
    "Step-Back": "Your task is to classify the comment as sarcastic or not. Describe the general situation/context BEFORE classifying & Provide your reasoning at the end. Comment: '{comment}' in response to: '{parent}'. RETURN Label: 0 for non-sarcastic, 1 for sarcastic. Reason:[1-2 sentences]."
}

# Few-Shot template
few_shot_prompt_template = "Given examples, classify the comment as sarcastic or not:\n"
for i, row in few_shot_examples.iterrows():
    if i in [1, 7, 9]:  # skip these indices
        continue
    label = row["label"]
    comment_example = row["clean_comment"]
    parent_example = row["parent_comment"]
    few_shot_prompt_template += f"Example {i+1}: Comment: '{comment_example}' in response to: '{parent_example}' Label: {label}\n"

few_shot_prompt_template += "\nComment: '{comment}' in response to: '{parent}'\nRETURN Label: 0 for non-sarcastic, 1 for sarcastic. Reason:[1-2 sentences]."

prompt_templates_direct["Few-Shot"] = few_shot_prompt_template

def run_chain_of_verification(model, comment, parent_comment, max_tokens=150):
    # Step 1: Initial classification
    initial_prompt = f"Classify the comment as sarcastic or not. Comment: '{comment}' in response to: '{parent_comment}'. RETURN Label: 0 for non-sarcastic, 1 for sarcastic. Reason:[1-2 sentences]."
    initial_output = model(prompt=initial_prompt, max_tokens=75)['choices'][0]['text']

    # Step 2: Generate verification questions
    verify_prompt = f"You classified the comment '{comment}' as '{initial_output}'. Generate 2-3 questions to verify this classification."
    verification_questions = model(prompt=verify_prompt, max_tokens=100)['choices'][0]['text']

    # Step 3: Final classification based on verification questions
    final_prompt = (
        f"Based on the initial classification '{initial_output}' and the following verification questions and your answers: '{verification_questions}', "
        f"provide a final classification for the comment '{comment}' in response to '{parent_comment}'. "
        "RETURN Label: 0 for non-sarcastic, 1 for sarcastic. Reason:[1-2 sentences]."
    )
    final_answer = model(prompt=final_prompt, max_tokens=150)['choices'][0]['text']

    return final_answer

def run_self_refine(model, comment, parent_comment, max_tokens=150):
    initial_prompt = f"Classify the comment as sarcastic or not. Comment: '{comment}' in response to: '{parent_comment}'. RETURN Label: 0 for non-sarcastic, 1 for sarcastic."
    initial_output = model(prompt=initial_prompt, max_tokens=50)['choices'][0]['text']

    refine_prompt = (
        f"You classified the comment '{comment}' as '{initial_output}'. Critique your output and refine it. "
        "RETURN Label: 0 for non-sarcastic, 1 for sarcastic. Reason:[1-2 sentences]."
    )
    refined_answer = model(prompt=refine_prompt, max_tokens=100)['choices'][0]['text']

    return refined_answer



"""### Pre-trained Model Interaction: (Sarcastic data tuned LLaMA)"""

from huggingface_hub import hf_hub_download

model_path = hf_hub_download(
    repo_id="mradermacher/llama-3.1-8b-sarcasm-GGUF",
    filename="llama-3.1-8b-sarcasm.Q4_K_M.gguf"
)
print(model_path)

import torch
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0))

!nvidia-smi

from llama_cpp import Llama
model = Llama(model_path=model_path, n_gpu_layers=40)

!nvidia-smi

results = []

for index, row in df_test.iterrows():
    comment = row['clean_comment']
    parent_comment = row['parent_comment'] if pd.notna(row['parent_comment']) else ""
    ori_label = row['label']

    for prompt_name, template in prompt_templates_direct.items():
        prompt_text = template.format(comment=comment, parent=parent_comment)

        output = model(prompt=prompt_text, max_tokens=150)
        print("\nOUTPUT: ", output)
        generated_text = output['choices'][0]['text']  # Extract text from response

        results.append({
            "prompt_type": prompt_name,
            "comment": comment,
            "parent_comment": parent_comment,
            "ori_label": ori_label,
            "model_output": generated_text
        })

results_df = pd.DataFrame(results)
results_df

results1=[]
for index, row in df_test.iterrows():
    comment = row['clean_comment']
    parent_comment = row['parent_comment'] if pd.notna(row['parent_comment']) else ""
    ori_label = row['label']

    for prompt_name, template in prompt_templates_direct.items():
        prompt_text = template.format(comment=comment, parent=parent_comment)

        generated_text = run_chain_of_verification(model, comment, parent_comment, max_tokens=150)

        results1.append({
            "prompt_type": prompt_name,
            "comment": comment,
            "parent_comment": parent_comment,
            "ori_label": ori_label,
            "model_output": generated_text
        })

# df_results_1 = pd.concat([results_df, pd.DataFrame(results1)], ignore_index=True)
df_2 = pd.DataFrame(results1)
df_2



"""### Troubleshooting & Observations


**Two common issues observed:**

1. **Loss of context:** When only the reply is given (Basic prompt), the model mislabels factual statements as sarcastic because it lacks the parent comment. **Solution:** Including context in prompts helps (Chain-of-Thought, Step-Back).

2. **Over-simplification in Rephrase prompts:** Rephrasing stripped away subtle contradictions such as "as amazing as it has been" vs. "trek my ass back", leading to missed sarcasm. **Solution:** Combining rephrase with explicit reasoning steps can help detect nuances.

**OBSERVATIONS**

*Chain-of-Verification* looks stronger than other prompting here as it corrected the shallow mistake Basic/Step-Back made, by explicitly checking itself.
"""

# Note: Since I used dataset that was already fine tuned for my purpose. I did not use fine-tuning step. Another reason being resource constraints for fine-tuning.
# Even prompt engineering took longer on colab than expected.



# results3=[]
# for index, row in df_test.iterrows():
#     comment = row['clean_comment']
#     parent_comment = row['parent_comment'] if pd.notna(row['parent_comment']) else ""
#     ori_label = row['label']

#     for prompt_name, template in prompt_templates_direct.items():
#         prompt_text = template.format(comment=comment, parent=parent_comment)

#         generated_text = run_self_refine(model, comment, parent_comment, max_tokens=150)

#         results3.append({
#             "prompt_type": prompt_name,
#             "comment": comment,
#             "parent_comment": parent_comment,
#             "ori_label": ori_label,
#             "model_output": generated_text
#         })

# df_3 = pd.DataFrame(results3)
# df_3

# # final_df = pd.concat([results_df, df_2, df_3], ignore_index=True)
# final_df = pd.concat([results_df, df_2], ignore_index=True)
# final_df.shape

